\subsection{Web Framework Architectures and Approaches to PSSR}

In traditional thread-per-request architectures, each incoming request is
handled by a dedicated thread. The web server maintains a thread pool from
which a thread is assigned to handle each request. As the load increases, the
number of active threads can grow rapidly, potentially exhausting the pool.
This can lead to performance and scalability issues, as the system may become
bogged down by context switching and thread management
overhead~\cite{kant2000scalable}. In the Java ecosystem, Spring MVC is one of
the most widely used frameworks that follow this model, according to several
reports such as the Stack Overflow 2024 Developer
Survey~\footnote{~\url{https://survey.stackoverflow.co/2024/technology\#1-web-frameworks-and-technologies}}.

On the other hand, in modern \textit{low-thread} architectures, the server uses
a small number of threads to handle a large number of requests.
\textit{Low-thread} servers, also known as
\textit{event-driven}~\cite{event-driven-servers}, offer a significant
advantage in efficiently managing a high number of concurrent I/O operations
with minimal resource usage.

The \textit{non-blocking} I/O model employed in low-thread servers is
well-suited for handling large volumes of data asynchronously~\cite{Meijer12}.
This combination of low-thread servers and asynchronous data models has
facilitated the development of highly scalable, responsive, and resilient web
applications capable of managing substantial data loads~\cite{Jin15}. The
prominence of this concept increased with the advent of Node.js in 2009, and
subsequently, various technologies adopted this approach in the Java ecosystem,
including Netty, Akka HTTP, Vert.X, and Spring WebFlux.
% Among these, Spring WebFlux stands out as the most widely used web framework in
% Java, according to surveys like JetBrains' State of Java report (2021) and
% community metrics from platforms like Github and StackOverflow.
The \textit{non-blocking} I/O model in low-thread servers functions optimally
only when HTTP handlers avoid blocking. Therefore, HTML templates need to be
proficient in dealing with the asynchronous APIs provided by data models. While
most legacy web templates struggle with asynchronous models, DSLs for HTML face
no such limitations, leveraging all constructions available in the host
programming language. However, the unexpected intertwining of asynchronous
handlers' completion and HTML builders' execution may potentially lead to
malformed HTML with an unexpected layout~\cite{wise2024pssr}.

An alternative approach involves utilizing user-level threads, while
maintaining a blocking I/O and a synchronous programming paradigm. However,
this approach still requires a user-level I/O subsystem capable of mitigating
system-level blocking, which is crucial for the performance of I/O-intensive
applications. This technique offers a lightweight solution for efficiently
managing a larger number of concurrent sessions by minimizing per-thread
overhead. In 2020, Karsten~\cite{karsten2020} demonstrated how this strategy
supports a synchronous programming style, effectively abstracting away the
complexities associated with managing continuations in asynchronous
programming.

Among mainstream technologies, the Kotlin programming language introduces a new
abstraction for managing coroutines and provides structured concurrency, which
ensures that coroutines are \textit{scoped}, \textit{cancellable}, and
\textit{coordinated} within a well-defined
lifecycle~\cite{elizarov2021coroutines}. Although this model embraces the
\texttt{async}/\texttt{await} feature~\cite{async_await}, enabling non-blocking
routines to mimic the structure of synchronous ones, it still lacks a
user-level I/O subsystem and relies on an explicit I/O dispatcher tied to a
dedicated thread pool that frees worker threads for handling processing tasks.
Moreover, web templates using their own templating dialects, such as JSP,
Thymeleaf, or Handlebars, are unable to take advantage of such constructs, as
they typically support only a limited subset of the host library's API—most
commonly just the \texttt{Iterable} interface.

Only Java virtual threads, introduced in
JEP~444\footnote{\url{https://openjdk.org/jeps/444}}, adopt a similar approach
to Karsten's proposal, using user-mode threads to preserve a synchronous
programming model while still allowing blocking I/O operations without tying up
platform threads. When a virtual thread performs a blocking I/O operation, the
JVM intercepts the call and transparently parks the virtual thread, freeing the
underlying platform thread to perform other tasks. Once the I/O operation
completes, the virtual thread is rescheduled on a platform thread and resumes
execution. This mechanism is enabled by the JVM's integration with non-blocking
system calls at the OS level, allowing developers to write traditional
synchronous code while benefiting from the scalability of non-blocking I/O.

\subsubsection{Spring MVC}

Spring MVC is a synchronous web framework built on the
thread-per-request model. When an HTTP request is received, it is handled by a
dedicated thread from the server’s thread pool (e.g., Tomcat, Jetty, or
Undertow). This thread is responsible for executing the full request lifecycle
synchronously, including invoking controllers, executing business logic, and
rendering the response view. Because the model is blocking, the thread remains
occupied throughout the request—even during I/O operations such as database
queries or external API calls—which can lead to performance bottlenecks under
high concurrency.

Controllers in Spring MVC typically return Java objects or models that are
processed by view resolvers in conjunction with template engines like JSP,
Thymeleaf, or FreeMarker. These templates generate the full HTML response in
one pass, which is then sent to the client only after all necessary data has
been gathered and rendered. By default, this architecture limits the ability to
perform PSSR, as traditional
rendering waits for all data before sending any output. This results in higher
latency for clients and less responsive page loads, particularly for
data-intensive views. However, Spring MVC provides a mechanism for response
streaming via the \texttt{StreamingResponseBody}\footnote{\url{https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/web/servlet/mvc/method/annotation/StreamingResponseBody.html}} interface, introduced in
Spring 4.2. When a controller method returns a \texttt{StreamingResponseBody},
Spring writes directly to the \texttt{HttpServletResponse} output stream,
allowing the server to send parts of the response incrementally as they become
available. This is particularly useful for:
\begin{itemize}
  \item Sending large responses without buffering the entire output in memory.
  \item Writing dynamic HTML in fragments as data is fetched or computed.
  \item Reducing Time to First Byte (TTFB) and improving perceived performance.
\end{itemize}

\begin{lstlisting}[
    language=Java,
    basicstyle=\scriptsize\ttfamily,
    numbers=none,
    caption={StreamingResponseBody handler in Spring MVC},
    label={lst:streaming-response-body}
]
  @GetMapping("/stream")
  fun handleStream(): StreamingResponseBody? {
      return StreamingResponseBody { outputStream ->
          for (i in 0..9) {
              val htmlFragment = "<p>Chunk " + i + "</p>\n"
              outputStream.write(htmlFragment.toByteArray())
              outputStream.flush() // ensure partial response is sent
              Thread.sleep(500) // simulate delay
          }
      }
  }
\end{lstlisting}

In the example shown in \autoref{lst:streaming-response-body}, HTML content is written and flushed in discrete chunks,
allowing the client to progressively render the response as it arrives, while
the server continues processing additional data.
However, this technique has two limitations. First, it does not eliminate the
blocking nature inherent in Spring MVC, as the handling thread remains active
during the streaming process.
Second, it is constrained by the servlet response buffer.
By default, most servlet containers (e.g., Tomcat) use a
response buffer size of approximately 8KB. Data written to the response output
stream is held in this buffer until it reaches capacity. Consequently, if the
total size of the initial HTML content is less than the buffer threshold, the
server will not transmit any data to the client until the buffer is filled.
This buffering behavior introduces a delay in sending the first chunk of
content, thereby negating the benefits of progressive rendering. In scenarios
where the rendered HTML template does not produce sufficient data to exceed the
buffer threshold early, PSSR becomes ineffective, and the client experiences a
delayed initial response.

\subsubsection{Spring WebFlux}

Spring WebFlux is a reactive web framework built on a non-blocking,
event-driven architecture that enables efficient handling of a large number of
concurrent connections with minimal resource usage. Unlike traditional
servlet-based stacks that rely on a thread-per-request model, WebFlux operates
on reactive runtimes like Netty, where a small, fixed-size event loop manages
all I/O events.
Incoming HTTP requests are routed to handler functions or annotated controllers,
which return reactive types such as \texttt{Mono<T>} and
\texttt{Flux<T>}—\texttt{Publisher} implementations provided by the Project Reactor
library~\cite{projectreactor}. These implementations adhere to the Reactive
Streams specification~\cite{ReactiveStreams}, enabling interoperability with
other compliant reactive stream libraries.
A \texttt{Mono} represents a single asynchronous value (or
none)~\cite{promise}, while a \texttt{Flux} represents a stream of zero or more values~\cite{rx-observable}. These
abstractions allow the entire request lifecycle—from controller invocation to
response rendering—to be orchestrated as a chain of non-blocking, asynchronous
operations. I/O-bound tasks such as database queries or external API calls do
not occupy threads during execution, enabling the framework to scale gracefully
under high load and maintain responsiveness even in resource-constrained
environments.

PSSR is natively supported in WebFlux via
\texttt{Flux}-based controllers. When a controller returns a
\texttt{Flux<String>} or another stream of HTML fragments, WebFlux can begin
streaming content to the client as soon as the first elements are emitted.
% This allows browsers to incrementally render parts of the response without waiting
% for the entire payload, significantly reducing Time to First Byte (TTFB) and
% improving user-perceived performance. By integrating PSSR directly into the
% reactive processing pipeline, WebFlux facilitates responsive and resilient web
% applications well-suited for modern microservices architectures.

\begin{lstlisting}[
    language=Java,
    basicstyle=\scriptsize\ttfamily,
    numbers=none,
    caption={Progressive Server-Side Rendering in Spring WebFlux},
    label={lst:pssr-webflux}
]
@GetMapping(value = "/pssr", produces = MediaType.TEXT_HTML_VALUE)
public Flux<String> renderChunks() {
    return Flux.range(1, 10)
               .delayElements(Duration.ofMillis(500))
               .map(i -> "<p>Chunk " + i + "</p>\n");
}
\end{lstlisting}

\autoref{lst:pssr-webflux} shows a method that emits one HTML chunk every 500 milliseconds. As
each chunk is generated, it is immediately written to the HTTP response,
allowing the client to begin rendering content even as more data is still being
produced. Unlike \texttt{StreamingResponseBody} in Spring MVC, which is
constrained by servlet buffer thresholds and blocking semantics, WebFlux
ensures that each emitted item is pushed to the client as soon as the network
is ready, without occupying a dedicated thread. Moreover, WebFlux integrates
seamlessly with reactive data sources such as R2DBC (Reactive Relational
Database Connectivity) and reactive NoSQL drivers, making it possible to build
end-to-end non-blocking applications. HTML builders and DSLs used in
conjunction with WebFlux must be designed to accommodate reactive streams,
ensuring that view generation does not violate the non-blocking contract by
performing blocking I/O or awaiting asynchronous operations imperatively.

\subsubsection{Quarkus}

Quarkus is a modern, cloud-native Java framework that supports both imperative
and reactive programming models. It is built on top of Vert.x,
which provides a non-blocking, event-driven runtime similar to Netty. Incoming
HTTP requests are processed asynchronously on a small, fixed-size event loop
thread pool, allowing the framework to handle many concurrent connections
efficiently without blocking threads. 
Quarkus provides support for reactive APIs like Mutiny~\cite{mutiny2021}, a
modern alternative to Spring Reactor~\cite{projectreactor}. Like Reactor,
Mutiny complies with the Reactive Streams specification~\cite{ReactiveStreams}.
For traditional imperative-style request handling, Quarkus provides integration
with JAX-RS~\cite{burke2013restful}, where resource methods can return synchronous types or
asynchronous constructs such as \texttt{CompletionStage}. To enable 
PSSR in imperative endpoints, Quarkus leverages the
JAX-RS \texttt{StreamingOutput} interface. By returning a
\texttt{StreamingOutput} instance, developers can write parts of the HTTP
response body incrementally as data becomes available. This approach allows the
server to flush HTML fragments progressively to the client, improving the
perceived responsiveness especially for long-running or large responses.
However, like other streaming mechanisms based on servlet buffers, the initial
data flush may be delayed until internal buffers (commonly around 8KB) are
filled. However, Quarkus allows configuring the buffer size to a smaller value, which
can help mitigate this issue.

\begin{lstlisting}[
  language=java,
  basicstyle=\scriptsize\ttfamily,
  numbers=none,
  caption={Progressive Server-Side Rendering in Quarkus using StreamingOutput},
  label={lst:pssr-quarkus}
]
@GET
@Path("/stream")
@Produces(MediaType.TEXT_HTML)
public StreamingOutput streamHtml() {
    return output -> {
        PrintWriter writer = new PrintWriter(output);
        for (int i = 1; i <= 5; i++) {
            writer.println("<p>Chunk " + i + "</p>");
            writer.flush(); // Flush each chunk incrementally
            Thread.sleep(500); // Simulate processing delay
        }
        writer.flush();
    };
}
\end{lstlisting}

\autoref{lst:pssr-quarkus} shows how \texttt{StreamingOutput} can be used to send
partial HTML content in chunks, allowing browsers to progressively render the
response while the server continues processing. Quarkus’ architecture ensures
that the underlying event loop threads are not blocked by these writes, as the
framework offloads blocking I/O operations to worker threads. This combination
of non-blocking event-driven runtime and incremental response streaming enables
efficient PSSR even within imperative programming styles.